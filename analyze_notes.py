#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¬”è®°åˆ†æå·¥å…· (Notes Analysis Tool)
åˆ†æTyporaç¬”è®°ä»“åº“çš„å†…å®¹ç»Ÿè®¡å’Œä¸»é¢˜åˆ†ç±»
"""

import os
import re
from pathlib import Path
from collections import defaultdict
from datetime import datetime


class NotesAnalyzer:
    """ç¬”è®°åˆ†æå™¨ç±»"""
    
    def __init__(self, repo_path="."):
        self.repo_path = Path(repo_path)
        self.notes = []
        self.stats = {
            "total_notes": 0,
            "total_lines": 0,
            "total_words": 0,
            "total_chars": 0,
            "topics": defaultdict(list)
        }
    
    def find_markdown_files(self):
        """æŸ¥æ‰¾æ‰€æœ‰markdownæ–‡ä»¶"""
        for md_file in self.repo_path.rglob("*.md"):
            # è·³è¿‡ .git ç›®å½•ã€README.md å’Œåˆ†ææŠ¥å‘Šæœ¬èº«
            if ".git" in str(md_file):
                continue
            if md_file.name == "README.md" and md_file.parent == self.repo_path:
                continue
            if md_file.name == "ç¬”è®°åˆ†ææŠ¥å‘Š.md":
                continue
            self.notes.append(md_file)
        return self.notes
    
    def analyze_file(self, file_path):
        """åˆ†æå•ä¸ªæ–‡ä»¶"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            lines = content.split('\n')
            words = len(re.findall(r'\S+', content))
            chars = len(content)
            
            # æå–æ ‡é¢˜
            headers = re.findall(r'^#{1,6}\s+(.+)$', content, re.MULTILINE)
            
            # æå–ä»£ç å—
            code_blocks = re.findall(r'```[\s\S]*?```', content)
            
            # æå–å›¾ç‰‡
            images = re.findall(r'!\[.*?\]\(.*?\)', content)
            
            return {
                "path": file_path,
                "lines": len(lines),
                "words": words,
                "chars": chars,
                "headers": headers,
                "code_blocks": len(code_blocks),
                "images": len(images)
            }
        except Exception as e:
            print(f"è¯»å–æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
            return None
    
    def categorize_by_topic(self):
        """æŒ‰ä¸»é¢˜åˆ†ç±»ç¬”è®°"""
        for note in self.notes:
            # è·å–ç›¸å¯¹è·¯å¾„çš„ç¬¬ä¸€çº§ç›®å½•ä½œä¸ºä¸»é¢˜
            relative_path = note.relative_to(self.repo_path)
            if len(relative_path.parts) > 1:
                topic = relative_path.parts[0]
            else:
                topic = "æ ¹ç›®å½•"
            self.stats["topics"][topic].append(note)
    
    def generate_report(self):
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        # æŸ¥æ‰¾æ‰€æœ‰ç¬”è®°
        self.find_markdown_files()
        self.categorize_by_topic()
        
        # åˆ†ææ¯ä¸ªç¬”è®°
        detailed_analysis = []
        for note in self.notes:
            analysis = self.analyze_file(note)
            if analysis:
                detailed_analysis.append(analysis)
                self.stats["total_lines"] += analysis["lines"]
                self.stats["total_words"] += analysis["words"]
                self.stats["total_chars"] += analysis["chars"]
        
        self.stats["total_notes"] = len(self.notes)
        
        # ç”ŸæˆæŠ¥å‘Šæ–‡æœ¬
        report = []
        report.append("# ğŸ“Š ç¬”è®°åˆ†ææŠ¥å‘Š\n")
        report.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n")
        report.append("---\n")
        
        # æ€»ä½“ç»Ÿè®¡
        report.append("## ğŸ“ˆ æ€»ä½“ç»Ÿè®¡\n")
        report.append(f"- **ç¬”è®°æ€»æ•°**: {self.stats['total_notes']} ç¯‡")
        report.append(f"- **æ€»è¡Œæ•°**: {self.stats['total_lines']:,} è¡Œ")
        report.append(f"- **æ€»å­—æ•°**: {self.stats['total_words']:,} å­—")
        report.append(f"- **æ€»å­—ç¬¦æ•°**: {self.stats['total_chars']:,} å­—ç¬¦")
        report.append(f"- **å¹³å‡æ¯ç¯‡ç¬”è®°**: {self.stats['total_lines']//self.stats['total_notes'] if self.stats['total_notes'] > 0 else 0} è¡Œ\n")
        
        # ä¸»é¢˜åˆ†ç±»ç»Ÿè®¡
        report.append("## ğŸ“š ä¸»é¢˜åˆ†ç±»ç»Ÿè®¡\n")
        report.append("| ä¸»é¢˜ | ç¬”è®°æ•°é‡ | å æ¯” |")
        report.append("|------|---------|------|")
        
        sorted_topics = sorted(self.stats["topics"].items(), key=lambda x: len(x[1]), reverse=True)
        for topic, notes in sorted_topics:
            percentage = len(notes) / self.stats["total_notes"] * 100
            report.append(f"| {topic} | {len(notes)} ç¯‡ | {percentage:.1f}% |")
        report.append("")
        
        # è¯¦ç»†ç¬”è®°åˆ—è¡¨
        report.append("## ğŸ“ è¯¦ç»†ç¬”è®°åˆ—è¡¨\n")
        
        # æŒ‰ä¸»é¢˜åˆ†ç»„æ˜¾ç¤º
        for topic, notes in sorted_topics:
            report.append(f"### {topic}\n")
            for note in notes:
                analysis = next((a for a in detailed_analysis if a["path"] == note), None)
                if analysis:
                    relative_path = note.relative_to(self.repo_path)
                    report.append(f"**{note.name}**")
                    report.append(f"- è·¯å¾„: `{relative_path}`")
                    report.append(f"- è¡Œæ•°: {analysis['lines']} | å­—æ•°: {analysis['words']} | ä»£ç å—: {analysis['code_blocks']} | å›¾ç‰‡: {analysis['images']}")
                    if analysis['headers']:
                        report.append(f"- ä¸»è¦ç« èŠ‚: {', '.join(analysis['headers'][:5])}")
                        if len(analysis['headers']) > 5:
                            report.append(f"  (è¿˜æœ‰ {len(analysis['headers']) - 5} ä¸ªç« èŠ‚...)")
                    report.append("")
        
        # æœ€è¯¦ç»†çš„ç¬”è®°ï¼ˆTop 5ï¼‰
        report.append("## ğŸ† æœ€è¯¦ç»†çš„ç¬”è®° (Top 5)\n")
        top_notes = sorted(detailed_analysis, key=lambda x: x["lines"], reverse=True)[:5]
        for i, note in enumerate(top_notes, 1):
            relative_path = note["path"].relative_to(self.repo_path)
            report.append(f"{i}. **{note['path'].name}** (`{relative_path}`)")
            report.append(f"   - {note['lines']} è¡Œ | {note['words']} å­— | {note['code_blocks']} ä»£ç å—\n")
        
        # å†…å®¹ç‰¹å¾åˆ†æ
        report.append("## ğŸ” å†…å®¹ç‰¹å¾åˆ†æ\n")
        total_code_blocks = sum(a["code_blocks"] for a in detailed_analysis)
        total_images = sum(a["images"] for a in detailed_analysis)
        report.append(f"- **ä»£ç å—æ€»æ•°**: {total_code_blocks} ä¸ª")
        report.append(f"- **å›¾ç‰‡æ€»æ•°**: {total_images} å¼ ")
        report.append(f"- **å¹³å‡æ¯ç¯‡ç¬”è®°ä»£ç å—æ•°**: {total_code_blocks/self.stats['total_notes']:.1f} ä¸ª")
        report.append(f"- **å¹³å‡æ¯ç¯‡ç¬”è®°å›¾ç‰‡æ•°**: {total_images/self.stats['total_notes']:.1f} å¼ \n")
        
        # å­¦ä¹ å»ºè®®
        report.append("## ğŸ’¡ å­¦ä¹ å»ºè®®\n")
        report.append("åŸºäºç¬”è®°åˆ†æï¼Œä»¥ä¸‹æ˜¯ä¸€äº›å»ºè®®ï¼š\n")
        
        if len(sorted_topics) > 0:
            top_topic = sorted_topics[0][0]
            report.append(f"1. **ä¸»è¦å­¦ä¹ æ–¹å‘**: ç›®å‰ `{top_topic}` æ˜¯ä½ çš„ä¸»è¦å­¦ä¹ é¢†åŸŸï¼Œå»ºè®®ç»§ç»­æ·±å…¥å­¦ä¹ ")
        
        avg_lines = self.stats['total_lines'] / self.stats['total_notes'] if self.stats['total_notes'] > 0 else 0
        if avg_lines < 50:
            report.append("2. **ç¬”è®°æ·±åº¦**: å½“å‰ç¬”è®°ç›¸å¯¹ç®€æ´ï¼Œå¯ä»¥è€ƒè™‘æ·»åŠ æ›´å¤šå®ä¾‹å’Œè¯¦ç»†è¯´æ˜")
        else:
            report.append("2. **ç¬”è®°æ·±åº¦**: ç¬”è®°å†…å®¹è¾ƒä¸ºå……å®ï¼Œä¿æŒè¿™ä¸ªè‰¯å¥½çš„è®°å½•ä¹ æƒ¯")
        
        if total_code_blocks / self.stats['total_notes'] > 2:
            report.append("3. **ä»£ç å®è·µ**: ç¬”è®°ä¸­åŒ…å«å¤§é‡ä»£ç ç¤ºä¾‹ï¼Œè¯´æ˜æ³¨é‡å®è·µï¼Œéå¸¸å¥½ï¼")
        
        report.append("4. **æŒç»­æ›´æ–°**: å»ºè®®å®šæœŸå›é¡¾å’Œæ›´æ–°ç¬”è®°ï¼Œå·©å›ºå­¦ä¹ æˆæœ\n")
        
        # ç»“æŸè¯­
        report.append("---\n")
        report.append("*æ­¤æŠ¥å‘Šç”±ç¬”è®°åˆ†æå·¥å…·è‡ªåŠ¨ç”Ÿæˆ* ğŸ“Š\n")
        
        return "\n".join(report)
    
    def save_report(self, output_file="ç¬”è®°åˆ†ææŠ¥å‘Š.md"):
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        report = self.generate_report()
        output_path = self.repo_path / output_file
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"âœ… åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {output_path}")
        return output_path


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description="ğŸ“Š ç¬”è®°åˆ†æå·¥å…· - åˆ†æTyporaç¬”è®°ä»“åº“çš„å†…å®¹ç»Ÿè®¡å’Œä¸»é¢˜åˆ†ç±»",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  python3 analyze_notes.py                    # åˆ†æå½“å‰ç›®å½•çš„ç¬”è®°
  python3 analyze_notes.py -o report.md       # æŒ‡å®šè¾“å‡ºæ–‡ä»¶å
  python3 analyze_notes.py -p /path/to/notes  # æŒ‡å®šç¬”è®°ç›®å½•

ç”Ÿæˆçš„æŠ¥å‘ŠåŒ…å«ï¼š
  âœ“ ç¬”è®°æ€»æ•°ã€è¡Œæ•°ã€å­—æ•°ç­‰ç»Ÿè®¡
  âœ“ ä¸»é¢˜åˆ†ç±»å’Œåˆ†å¸ƒ
  âœ“ è¯¦ç»†ç¬”è®°åˆ—è¡¨
  âœ“ å†…å®¹ç‰¹å¾åˆ†æ
  âœ“ å­¦ä¹ å»ºè®®
        """
    )
    
    parser.add_argument(
        "-p", "--path",
        default=".",
        help="ç¬”è®°ç›®å½•è·¯å¾„ (é»˜è®¤: å½“å‰ç›®å½•)"
    )
    
    parser.add_argument(
        "-o", "--output",
        default="ç¬”è®°åˆ†ææŠ¥å‘Š.md",
        help="è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶å (é»˜è®¤: ç¬”è®°åˆ†ææŠ¥å‘Š.md)"
    )
    
    args = parser.parse_args()
    
    print("ğŸ” å¼€å§‹åˆ†æç¬”è®°...")
    analyzer = NotesAnalyzer(args.path)
    analyzer.save_report(args.output)
    print("âœ¨ åˆ†æå®Œæˆï¼")


if __name__ == "__main__":
    main()
